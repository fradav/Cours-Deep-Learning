{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Neural-Networks\" data-toc-modified-id=\"Neural-Networks-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Neural Networks</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Neural Networks\n",
    "===============\n",
    "\n",
    "Neural networks can be constructed using the ``torch.nn`` package.\n",
    "\n",
    "Now that you had a glimpse of ``autograd``, ``nn`` depends on\n",
    "``autograd`` to define models and differentiate them.\n",
    "An ``nn.Module`` contains layers, and a method ``forward(input)``\\ that\n",
    "returns the ``output``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, look at this network that classifies digit images:\n",
    "\n",
    "![convnet](../_static/img/mnist.png)\n",
    "\n",
    "It is a simple feed-forward network. It takes the input, feeds it\n",
    "through several layers one after the other, and then finally gives the\n",
    "output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A typical training procedure for a neural network is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Define the neural network that has some learnable parameters (or\n",
    "  weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Iterate over a dataset of inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Process input through the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Compute the loss (how far is the output from being correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Propagate gradients back into the network’s parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Update the weights of the network, typically using a simple update rule:\n",
    "  ``weight = weight - learning_rate * gradient``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define the network\n",
    "------------------\n",
    "\n",
    "Let’s define this network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You just have to define the ``forward`` function, and the ``backward``\n",
    "function (where gradients are computed) is automatically defined for you\n",
    "using ``autograd``.\n",
    "You can use any of the Tensor operations in the ``forward`` function.\n",
    "\n",
    "The learnable parameters of a model are returned by ``net.parameters()``\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[[[ 6.7859e-02, -1.9005e-01,  1.8810e-01,  1.2923e-02,  8.9450e-03],\n",
      "          [-3.2996e-02, -1.3114e-01,  1.1513e-01, -1.0494e-01,  7.1926e-02],\n",
      "          [-8.4603e-02, -1.6450e-01,  5.2596e-02, -6.8345e-02, -1.5887e-01],\n",
      "          [ 1.4162e-01,  6.5854e-02, -4.4675e-02,  1.1221e-01,  1.6472e-02],\n",
      "          [-9.0864e-02, -1.1963e-01,  1.6023e-02,  1.9505e-01, -5.3095e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6647e-01,  1.8772e-01,  4.1453e-02, -1.0453e-01, -6.1271e-02],\n",
      "          [ 1.9138e-01, -3.7036e-02, -1.8216e-02, -8.0275e-02, -3.9518e-02],\n",
      "          [ 1.1836e-01,  1.4361e-01,  3.8874e-02,  1.1272e-01,  3.6754e-02],\n",
      "          [ 1.7342e-02,  1.8355e-01, -6.9731e-02,  1.8142e-03,  4.8517e-02],\n",
      "          [ 1.3354e-01, -1.3123e-01, -9.5407e-02, -1.7106e-01, -1.1009e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8091e-01, -1.5856e-01,  1.5622e-01,  5.2095e-02,  1.5880e-01],\n",
      "          [ 1.8159e-01, -1.3252e-01,  1.1634e-01,  1.5389e-01, -1.6238e-01],\n",
      "          [-1.7970e-01, -4.8288e-02,  1.9923e-01,  6.2833e-02, -1.1773e-01],\n",
      "          [ 2.5203e-02, -1.4416e-01,  1.8441e-01,  8.4829e-02, -1.8186e-01],\n",
      "          [ 7.6809e-02, -4.1912e-02, -1.0651e-01, -1.5490e-01, -6.7093e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.3528e-01, -2.3538e-02,  1.2213e-01,  1.1658e-01,  8.5840e-02],\n",
      "          [-6.1797e-02,  6.3212e-02, -1.3951e-01,  9.7108e-02,  1.5059e-01],\n",
      "          [-5.8351e-03,  8.4192e-05,  1.4057e-01,  7.7183e-02,  4.9790e-02],\n",
      "          [-5.2907e-02,  3.4174e-02,  2.3181e-02,  1.9831e-01,  2.6256e-02],\n",
      "          [-1.5182e-01,  1.6531e-01,  1.3799e-01, -1.4652e-01, -1.5169e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1680e-02, -8.8775e-02,  2.7048e-02,  1.5494e-01,  1.4895e-01],\n",
      "          [-3.9487e-03,  1.2865e-01,  1.6481e-01,  2.1917e-02, -1.9916e-01],\n",
      "          [-1.1557e-01,  1.1652e-01,  5.3403e-03,  1.5616e-01, -1.2141e-01],\n",
      "          [-8.0182e-02,  6.5489e-02, -2.9143e-02,  1.5819e-01, -8.6824e-02],\n",
      "          [ 1.6346e-01,  1.6408e-01,  1.0959e-01, -3.7340e-03,  7.0282e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2781e-02,  1.8091e-01,  1.8709e-01, -1.8869e-01,  1.4149e-01],\n",
      "          [-7.3848e-02,  1.0288e-02, -1.3038e-01, -1.9502e-01, -1.2815e-01],\n",
      "          [ 3.9228e-02,  2.4825e-02, -1.3809e-01, -1.0910e-02, -1.5166e-01],\n",
      "          [ 9.1991e-02, -1.4077e-01,  5.4018e-02, -1.8798e-01, -1.6598e-01],\n",
      "          [-1.3172e-01,  4.4146e-04,  4.4940e-02, -1.1876e-01,  1.0857e-01]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1396, -0.1975, -0.1907,  0.1961, -0.1234, -0.0169],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[[[ 3.2648e-02, -1.4569e-02,  1.8302e-02, -3.0505e-03,  4.9086e-02],\n",
      "          [-1.9284e-02, -4.1506e-02,  2.4442e-02, -6.3035e-02,  3.7953e-02],\n",
      "          [ 2.4900e-02, -4.1181e-02, -6.6561e-02,  2.7296e-02,  6.9604e-02],\n",
      "          [ 6.4989e-02,  1.1330e-02, -7.1011e-03, -6.2279e-02, -4.9471e-02],\n",
      "          [ 2.8585e-02, -2.8044e-02,  4.2148e-02, -2.3049e-02,  1.5728e-02]],\n",
      "\n",
      "         [[ 5.4683e-02, -5.3170e-03, -4.3383e-02,  6.2068e-02,  5.3938e-02],\n",
      "          [-4.5300e-02,  5.9569e-02,  4.4783e-02, -1.4844e-02, -4.2306e-02],\n",
      "          [ 5.0678e-02,  2.2701e-02,  4.1740e-03,  6.9514e-02,  1.6098e-03],\n",
      "          [-1.8353e-02, -6.1262e-02, -3.3367e-02,  5.5221e-02,  5.7214e-02],\n",
      "          [-6.4726e-02, -7.7560e-02, -2.9718e-02, -2.2672e-02,  6.7917e-02]],\n",
      "\n",
      "         [[-5.4250e-02,  4.4595e-02,  2.4518e-02, -6.7069e-02, -2.4550e-02],\n",
      "          [ 6.9734e-02,  2.9104e-02, -5.8783e-02, -2.3246e-02,  2.4931e-02],\n",
      "          [-7.9847e-02,  2.8433e-02, -3.3265e-02, -2.0248e-02,  3.9811e-02],\n",
      "          [-8.2034e-03,  1.5539e-02, -1.3091e-02,  1.8874e-03,  1.1427e-02],\n",
      "          [ 3.5911e-02, -4.8656e-02,  2.7830e-02,  7.8816e-02, -1.5691e-02]],\n",
      "\n",
      "         [[ 1.0447e-03, -2.8261e-02, -2.5975e-02,  6.2502e-02, -2.8064e-02],\n",
      "          [-6.2088e-02, -2.9317e-02, -5.5412e-02,  4.2242e-02,  3.5555e-02],\n",
      "          [ 5.5046e-02,  2.4657e-02, -5.3341e-02, -5.9347e-02, -3.1492e-02],\n",
      "          [-3.7444e-02, -1.0425e-02, -1.6925e-02, -2.7409e-03, -1.8496e-02],\n",
      "          [ 3.5931e-02, -4.6356e-02,  3.1165e-03, -3.5294e-02,  5.5553e-02]],\n",
      "\n",
      "         [[ 6.5780e-02,  3.7461e-02, -2.4331e-02, -5.8988e-02,  6.1870e-02],\n",
      "          [-2.1585e-02,  2.3761e-03,  2.3385e-02, -2.7088e-02,  7.8382e-02],\n",
      "          [ 5.3458e-02,  1.6295e-02,  1.5437e-02, -6.5391e-02,  4.1925e-02],\n",
      "          [-7.2514e-02,  3.4587e-02, -3.2328e-02, -7.3110e-02,  2.3648e-02],\n",
      "          [-1.2580e-02, -3.7655e-02,  2.6425e-02, -4.1004e-02, -5.8895e-03]],\n",
      "\n",
      "         [[-6.3642e-02,  5.0670e-02, -2.2543e-02, -7.2401e-02,  1.3258e-02],\n",
      "          [ 6.2327e-02,  7.6888e-02,  6.9365e-02, -3.7283e-02,  2.9053e-02],\n",
      "          [ 5.3516e-02, -3.0430e-02, -3.1743e-02, -5.7244e-02, -8.0240e-02],\n",
      "          [-2.3772e-02,  3.1882e-02,  4.2497e-02, -4.9569e-02, -4.0368e-03],\n",
      "          [-4.0120e-02, -1.1633e-02,  4.1317e-02, -5.4078e-02, -1.6093e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5274e-02, -1.1709e-02, -2.7708e-02, -2.5129e-02,  6.6161e-02],\n",
      "          [-4.8311e-02, -6.9419e-02,  4.3594e-04,  2.1258e-02, -6.5024e-02],\n",
      "          [-3.0127e-02, -6.3463e-02, -6.0086e-02, -1.6815e-03, -2.1866e-03],\n",
      "          [ 5.4578e-03, -7.4137e-02, -2.2340e-02, -6.4808e-02,  4.8089e-02],\n",
      "          [-5.6067e-02,  6.2175e-02, -4.4892e-03,  1.0481e-02,  1.3872e-02]],\n",
      "\n",
      "         [[ 2.9561e-02, -5.8435e-02,  7.9913e-02,  2.8627e-03, -8.7410e-03],\n",
      "          [-1.3467e-02,  5.0484e-02, -6.2873e-02, -7.4103e-02, -7.0337e-03],\n",
      "          [ 5.4107e-02,  4.8918e-02,  3.5667e-02,  7.6133e-02,  5.4562e-02],\n",
      "          [ 5.3803e-02,  5.2111e-02,  6.9305e-02,  3.3940e-02,  8.5685e-03],\n",
      "          [-2.3202e-03,  5.0355e-02, -4.1247e-02,  2.2407e-02, -6.7802e-02]],\n",
      "\n",
      "         [[ 7.3375e-03,  7.1967e-02, -4.2677e-02,  5.5768e-02, -4.0444e-02],\n",
      "          [-3.6563e-02, -5.0594e-02,  5.4675e-02,  3.6047e-02, -1.1510e-02],\n",
      "          [ 5.3362e-02, -2.3861e-02,  1.9983e-02, -3.6475e-02, -8.3939e-03],\n",
      "          [-3.6710e-02,  6.0440e-02, -6.8701e-02, -7.9329e-02, -1.5791e-02],\n",
      "          [-5.2451e-02,  2.3535e-02, -3.3921e-02, -2.8132e-02,  3.6370e-02]],\n",
      "\n",
      "         [[ 2.0265e-03,  5.6711e-02,  2.0080e-02, -7.2065e-02, -9.9041e-03],\n",
      "          [ 3.3406e-02, -7.9602e-05, -4.4243e-02, -4.8918e-03, -4.5972e-02],\n",
      "          [-5.9983e-02,  3.0654e-02,  8.0063e-02, -6.9062e-02,  3.1488e-02],\n",
      "          [-6.8581e-02, -5.6063e-02, -6.2016e-02, -3.6276e-02, -7.7855e-02],\n",
      "          [-7.5464e-02, -2.9073e-02,  5.6892e-02,  4.0770e-02, -3.9262e-02]],\n",
      "\n",
      "         [[-7.9992e-04,  8.0242e-02,  2.2608e-02, -5.9474e-02, -2.1622e-02],\n",
      "          [ 3.8709e-04,  5.5280e-02, -7.2333e-02,  8.8661e-03,  2.5640e-02],\n",
      "          [ 6.1704e-02, -6.7148e-02,  6.1328e-03, -3.3959e-02,  4.0082e-03],\n",
      "          [-1.7978e-02,  7.3866e-02,  4.9952e-02, -4.0709e-02, -7.4013e-02],\n",
      "          [ 7.6413e-02, -6.8747e-02,  6.3927e-02,  7.5185e-02, -6.5012e-02]],\n",
      "\n",
      "         [[-6.7209e-02,  2.7382e-03, -4.9641e-02,  4.3429e-02,  1.3355e-02],\n",
      "          [-6.9667e-02, -2.4958e-02, -1.7846e-02, -4.0916e-02, -3.4403e-02],\n",
      "          [-2.2284e-02,  3.8883e-02,  7.8339e-02,  1.9695e-02,  3.9442e-02],\n",
      "          [ 1.9426e-02, -5.8787e-02,  8.1505e-02, -3.8374e-02,  7.3802e-02],\n",
      "          [ 4.0350e-02,  8.1209e-03,  6.9142e-02,  4.7756e-02,  5.7117e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5898e-02,  3.1527e-02, -6.4420e-02, -4.5024e-02,  5.6699e-02],\n",
      "          [ 7.7173e-02,  7.7554e-02, -9.9489e-03,  6.8822e-02,  5.8567e-02],\n",
      "          [-8.0626e-02,  3.2834e-03,  5.3303e-02, -3.4855e-02, -3.7169e-02],\n",
      "          [ 7.7432e-02, -7.5339e-03, -3.8214e-02,  6.3023e-02, -3.6679e-02],\n",
      "          [ 5.5614e-02, -1.2627e-02,  7.4966e-03, -6.5891e-02,  3.1900e-02]],\n",
      "\n",
      "         [[ 4.2853e-02, -5.0718e-02,  5.9631e-02,  4.1533e-02, -8.0497e-02],\n",
      "          [ 3.5764e-02, -3.7803e-03, -2.5191e-02, -1.3217e-02, -7.6315e-02],\n",
      "          [ 6.4779e-02,  7.7041e-02, -2.7618e-02, -7.6581e-02,  7.6441e-02],\n",
      "          [-8.0589e-02, -4.0085e-02,  8.6249e-04,  7.0095e-04, -7.3472e-02],\n",
      "          [-6.4895e-02, -4.1782e-02, -6.1004e-02, -3.3228e-02,  6.7232e-02]],\n",
      "\n",
      "         [[ 2.8432e-02,  4.2976e-02, -7.7952e-02, -5.6215e-03,  4.3188e-02],\n",
      "          [-4.1241e-02,  3.8901e-02,  1.7159e-02,  4.6997e-02,  7.7193e-02],\n",
      "          [ 6.2546e-02,  5.5034e-03, -7.1887e-02, -1.5411e-02,  5.4044e-02],\n",
      "          [ 3.0209e-02,  7.4381e-02,  6.8138e-02, -6.7583e-02, -6.3917e-02],\n",
      "          [ 7.4848e-02, -6.1921e-02, -2.7952e-02, -4.3909e-02,  3.6017e-02]],\n",
      "\n",
      "         [[ 4.2878e-02,  4.1628e-02, -6.4986e-02,  2.5222e-02, -2.8007e-02],\n",
      "          [-1.8161e-02,  7.2792e-02,  3.7180e-02, -2.1143e-02,  3.0115e-02],\n",
      "          [-3.9624e-02, -3.6592e-02,  7.1809e-02, -4.6543e-02, -5.6584e-02],\n",
      "          [-7.8972e-02,  6.2007e-02, -2.2937e-02, -2.6558e-02,  2.1150e-02],\n",
      "          [ 3.2646e-02,  4.4319e-02,  7.9048e-02, -4.2449e-02, -6.4566e-02]],\n",
      "\n",
      "         [[ 5.4877e-02, -1.2073e-02, -4.0072e-02, -4.9167e-02,  3.8132e-02],\n",
      "          [ 5.8780e-02, -2.9911e-02, -9.5033e-03,  3.4469e-02, -6.3822e-02],\n",
      "          [-6.4269e-02,  5.2026e-02, -2.5843e-02, -4.8423e-02, -2.8952e-02],\n",
      "          [ 2.2604e-02,  7.8288e-02,  1.0247e-02, -8.1420e-02, -8.0849e-02],\n",
      "          [ 5.7599e-02,  1.2134e-02,  2.8743e-02,  2.4107e-02,  4.7417e-03]],\n",
      "\n",
      "         [[ 6.6847e-02,  5.0150e-02, -3.4378e-02, -2.9084e-02,  6.3950e-03],\n",
      "          [-5.6481e-03, -7.4613e-02, -1.9241e-02, -4.3731e-02, -1.6101e-03],\n",
      "          [-3.6883e-02,  7.0822e-02,  7.1737e-02,  6.2351e-02, -7.1629e-02],\n",
      "          [-6.4592e-02, -4.8113e-02, -3.5129e-02, -5.4212e-02,  6.0295e-02],\n",
      "          [ 3.8017e-02,  7.9326e-02, -2.0245e-02,  1.4368e-02,  3.5400e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.3031e-02,  1.8212e-02,  1.0296e-02, -3.8186e-02,  3.9744e-02],\n",
      "          [ 3.6161e-02, -3.6142e-02,  5.9462e-02,  7.2704e-02,  6.3920e-03],\n",
      "          [ 6.0080e-02,  6.0445e-02, -6.5270e-02, -4.2593e-02, -2.7848e-02],\n",
      "          [ 6.9565e-02,  6.7861e-02,  1.6699e-02,  4.2509e-02, -1.0989e-02],\n",
      "          [-7.2340e-02,  2.9663e-02,  7.6003e-04,  5.1983e-02, -2.1114e-02]],\n",
      "\n",
      "         [[ 2.0294e-02,  1.4964e-02,  5.4621e-02,  4.9175e-03, -3.2123e-02],\n",
      "          [-2.2475e-02,  5.9903e-02, -1.8242e-02,  7.7325e-02,  3.1460e-02],\n",
      "          [ 1.9907e-02, -8.2992e-03, -7.0362e-02,  4.0165e-02,  3.6462e-02],\n",
      "          [-4.2220e-02, -6.5757e-03,  6.0862e-02,  6.5861e-02, -1.0986e-02],\n",
      "          [ 8.0235e-02,  3.4465e-02, -2.9051e-02, -4.4636e-02, -4.8815e-02]],\n",
      "\n",
      "         [[ 1.5731e-02,  4.9630e-02,  3.9321e-02, -5.1214e-02,  7.4842e-02],\n",
      "          [-1.9761e-02,  5.4890e-02, -1.1811e-03, -5.2313e-02, -5.4400e-02],\n",
      "          [ 1.5879e-02,  7.5470e-02, -1.6417e-02, -4.9497e-02, -3.5232e-02],\n",
      "          [-1.4267e-03, -4.1341e-02, -6.8540e-02, -1.6091e-02,  6.0553e-03],\n",
      "          [-2.9203e-02, -6.4657e-03, -7.3976e-02,  2.7092e-02,  1.3543e-02]],\n",
      "\n",
      "         [[ 7.0357e-02,  1.2938e-02, -5.9930e-02, -7.9697e-02, -7.4514e-02],\n",
      "          [-1.2624e-02, -4.9626e-02, -3.1494e-02, -1.1986e-02,  4.5568e-02],\n",
      "          [-5.5445e-02,  5.5378e-02, -3.1953e-02, -7.9538e-02, -7.4216e-02],\n",
      "          [-3.0423e-02,  5.8339e-02, -7.0029e-03,  5.0556e-02,  4.7550e-02],\n",
      "          [-4.0252e-03, -7.1801e-02,  7.6039e-02, -4.3188e-02,  6.2295e-02]],\n",
      "\n",
      "         [[-1.4590e-02, -7.2032e-02,  4.5360e-02,  5.1766e-02,  3.3187e-02],\n",
      "          [ 6.7313e-02,  1.8919e-02, -5.9621e-02, -4.8822e-02, -3.2392e-02],\n",
      "          [ 3.1682e-02,  4.0138e-03, -2.1239e-02, -6.7683e-02, -5.7090e-02],\n",
      "          [-4.5519e-02,  6.9948e-02, -7.8359e-02, -4.6801e-02,  4.8857e-02],\n",
      "          [-2.6659e-02,  5.3316e-02, -2.9781e-02, -3.4845e-02,  4.9048e-02]],\n",
      "\n",
      "         [[-2.6259e-02,  6.9251e-02,  7.1342e-02, -3.6018e-02,  2.4556e-02],\n",
      "          [ 7.5799e-02, -2.4696e-02,  5.7689e-02, -3.1850e-02, -1.0464e-02],\n",
      "          [ 7.9674e-03,  1.7674e-02, -7.6627e-02,  2.9402e-03, -7.7420e-03],\n",
      "          [-4.3214e-02, -6.4079e-02, -2.8154e-02, -6.2691e-02,  2.3584e-02],\n",
      "          [-3.6709e-02, -4.8309e-02,  5.0313e-02,  1.6177e-02,  1.9334e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3952e-02,  7.5145e-02,  3.4492e-02,  8.0167e-02, -3.4174e-02],\n",
      "          [-4.8758e-02,  3.0676e-02, -3.9326e-02, -6.5193e-03,  3.0984e-02],\n",
      "          [ 1.0888e-02, -4.8136e-02, -4.7437e-02,  6.2825e-02, -3.3508e-02],\n",
      "          [-1.1241e-02,  3.5660e-02,  4.6254e-02, -3.2697e-02,  5.7451e-02],\n",
      "          [-7.6941e-02,  2.2070e-02, -3.2631e-02, -2.0744e-02, -8.6046e-03]],\n",
      "\n",
      "         [[ 4.8991e-02, -6.8690e-02,  4.2322e-02,  1.2417e-02, -5.9846e-02],\n",
      "          [-6.9943e-02, -8.5488e-03, -6.0448e-02,  5.3298e-02, -4.7796e-02],\n",
      "          [ 5.5976e-02,  2.3881e-02, -7.4359e-02,  3.3486e-02,  5.2688e-02],\n",
      "          [ 7.8701e-02, -2.1333e-02, -4.3030e-02, -5.3261e-02,  4.7528e-02],\n",
      "          [-4.1862e-02, -2.2759e-02, -8.0455e-02,  2.9820e-03,  4.2247e-02]],\n",
      "\n",
      "         [[-5.3173e-02, -2.6817e-02, -7.8180e-02,  6.3791e-02,  7.7611e-02],\n",
      "          [ 6.4649e-02,  4.3924e-02, -6.0486e-02,  2.3623e-02,  2.8202e-02],\n",
      "          [-6.3910e-02,  7.8105e-02, -7.8716e-02, -7.1844e-02, -5.7657e-02],\n",
      "          [ 6.8775e-02,  8.1169e-02,  3.8056e-02, -4.0818e-02,  1.3602e-02],\n",
      "          [-3.5565e-02,  7.1645e-02,  6.7554e-03, -1.8283e-02, -3.9302e-02]],\n",
      "\n",
      "         [[-7.0129e-02, -7.0400e-02,  3.8529e-02,  7.0662e-02,  3.6957e-02],\n",
      "          [ 2.9249e-02,  1.0599e-02, -8.1151e-02, -7.3105e-02,  3.5323e-02],\n",
      "          [ 2.9217e-02,  1.4239e-02, -2.5387e-03, -3.4942e-02, -5.0074e-02],\n",
      "          [ 8.4796e-03, -1.0564e-02,  2.8666e-02, -6.3046e-02,  2.4176e-02],\n",
      "          [-1.0155e-02,  7.0059e-02,  2.8065e-02,  4.5310e-02, -1.8038e-02]],\n",
      "\n",
      "         [[-8.9643e-03, -7.1290e-03,  5.6099e-02,  2.9708e-02,  4.5316e-02],\n",
      "          [ 4.2631e-02,  4.1127e-02,  2.6271e-02, -7.9404e-02,  6.4183e-02],\n",
      "          [ 1.8753e-02, -3.5647e-03, -1.8322e-02,  5.9735e-02,  7.3249e-02],\n",
      "          [ 1.9572e-02,  7.3670e-02,  1.3241e-02, -1.5089e-02,  4.1934e-02],\n",
      "          [-2.0666e-02, -3.6485e-02, -3.0763e-02, -6.7614e-02,  4.2810e-02]],\n",
      "\n",
      "         [[ 4.8784e-02,  4.0199e-03,  3.0873e-02,  3.0154e-02,  8.1125e-02],\n",
      "          [ 2.9104e-03,  6.9310e-02, -6.3355e-03, -2.8338e-02, -2.4524e-04],\n",
      "          [-4.8575e-02, -5.6163e-02, -1.9924e-03, -5.9546e-03, -5.1964e-02],\n",
      "          [-5.7233e-02,  5.0703e-02, -3.2362e-02, -3.6577e-02, -2.8356e-02],\n",
      "          [-3.3426e-02,  7.2663e-02,  8.3837e-03,  6.2309e-02,  6.3488e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5913e-02,  5.1058e-02,  1.8704e-03,  9.3215e-03,  6.1356e-02],\n",
      "          [ 1.0585e-02, -7.0943e-02,  4.1315e-02, -1.6328e-02, -2.4048e-02],\n",
      "          [-2.7163e-02, -8.4332e-03, -5.4723e-03, -1.4411e-02,  4.8624e-02],\n",
      "          [-4.2172e-02, -4.4346e-02,  2.2525e-02,  9.3996e-03,  6.3965e-02],\n",
      "          [-6.6049e-02, -2.6373e-02, -4.2297e-02, -6.5317e-02, -5.9523e-02]],\n",
      "\n",
      "         [[-4.9852e-02,  2.6797e-02,  9.6333e-04, -4.1562e-02,  4.7049e-02],\n",
      "          [ 1.3104e-02, -5.8879e-02, -6.6652e-02, -5.5705e-02, -1.1194e-02],\n",
      "          [-2.5644e-02,  9.2832e-03,  4.7754e-02,  5.9329e-02,  1.0220e-02],\n",
      "          [ 4.1135e-02, -3.1374e-02,  7.1244e-02, -7.3188e-02, -3.8910e-02],\n",
      "          [ 4.6223e-02,  2.5702e-02, -4.4842e-02, -6.6645e-02, -3.5434e-02]],\n",
      "\n",
      "         [[-2.7374e-03,  5.9722e-03, -3.0113e-02,  6.6144e-02, -5.9930e-02],\n",
      "          [ 7.0763e-02, -1.2723e-02, -1.9783e-02, -4.5110e-02, -6.0253e-02],\n",
      "          [-1.7444e-02, -3.9106e-02,  7.5556e-02,  5.4651e-02,  2.1272e-02],\n",
      "          [-5.0999e-03,  1.1614e-02, -5.0515e-02, -2.0010e-02, -5.5816e-02],\n",
      "          [-1.3578e-02,  7.6734e-02,  1.0493e-02, -4.7100e-02, -3.0561e-03]],\n",
      "\n",
      "         [[-1.5202e-03,  5.4816e-02, -6.7423e-02, -5.4731e-02,  1.5454e-03],\n",
      "          [ 7.3178e-02,  9.3574e-03,  2.9054e-02,  6.2856e-02, -1.6219e-02],\n",
      "          [-6.1013e-02,  3.6089e-02,  7.1052e-02, -4.7786e-02, -5.7243e-02],\n",
      "          [-5.0768e-02,  3.1670e-02,  5.9383e-02, -2.6469e-02,  7.7534e-02],\n",
      "          [-2.1071e-02,  2.0135e-02, -6.9644e-03, -2.8297e-02, -6.5546e-02]],\n",
      "\n",
      "         [[ 4.9563e-02,  1.0356e-02, -4.1470e-02,  1.7374e-02,  4.2843e-02],\n",
      "          [-5.4793e-02,  7.2812e-02,  1.2892e-03,  7.2822e-02,  7.0863e-02],\n",
      "          [ 2.7552e-02, -7.1992e-02, -7.7502e-02, -2.2332e-02,  3.2579e-02],\n",
      "          [ 2.7841e-02, -2.0180e-02,  4.3545e-02,  7.9416e-02,  7.5280e-02],\n",
      "          [ 7.5466e-02,  6.5127e-02, -4.5621e-02,  6.6765e-02,  4.4638e-02]],\n",
      "\n",
      "         [[-7.9985e-02,  5.4346e-02, -5.6088e-02,  7.5329e-02, -6.9513e-02],\n",
      "          [ 2.1279e-02,  5.0217e-02, -6.0809e-02, -3.5399e-02, -7.4079e-02],\n",
      "          [ 3.9058e-02, -6.0569e-02, -4.5662e-02,  4.6135e-02,  7.8469e-02],\n",
      "          [ 3.0796e-02,  1.6131e-02,  5.5142e-02, -7.4972e-02,  4.8850e-02],\n",
      "          [-4.0911e-02, -4.0748e-02, -3.0225e-02, -5.6054e-02, -2.7328e-02]]]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0523,  0.0725, -0.0674, -0.0394,  0.0479,  0.0112,  0.0757, -0.0668,\n",
      "        -0.0210,  0.0568,  0.0530, -0.0336, -0.0722, -0.0480, -0.0419, -0.0769],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-4.4485e-02, -7.4257e-03,  6.4532e-03,  ..., -2.9831e-02,\n",
      "          1.8781e-03,  3.2967e-03],\n",
      "        [-4.5000e-02, -4.2950e-02,  4.6725e-02,  ..., -4.1503e-03,\n",
      "          4.8603e-02, -7.7348e-05],\n",
      "        [-4.2683e-02, -3.2550e-02, -7.6103e-03,  ..., -4.8666e-03,\n",
      "          1.0472e-02, -4.3573e-03],\n",
      "        ...,\n",
      "        [ 4.4660e-02, -1.1686e-02,  3.3855e-02,  ..., -1.1256e-02,\n",
      "          1.5967e-02,  1.3254e-02],\n",
      "        [ 1.5472e-03,  4.6990e-02,  3.1463e-02,  ...,  3.9457e-03,\n",
      "         -3.0948e-02, -2.8706e-02],\n",
      "        [-4.4526e-02,  3.0709e-02,  3.2780e-02,  ...,  4.1131e-02,\n",
      "          1.8489e-02,  1.8873e-03]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0444, -0.0159, -0.0254, -0.0079,  0.0346, -0.0111, -0.0037,  0.0251,\n",
      "         0.0007, -0.0241, -0.0334,  0.0423,  0.0282, -0.0433,  0.0233,  0.0293,\n",
      "        -0.0396, -0.0272, -0.0326, -0.0385,  0.0308,  0.0174, -0.0246, -0.0401,\n",
      "        -0.0258,  0.0216, -0.0257, -0.0397,  0.0017, -0.0342,  0.0109,  0.0361,\n",
      "        -0.0327,  0.0287, -0.0152,  0.0221,  0.0355, -0.0137, -0.0149, -0.0101,\n",
      "         0.0449,  0.0450, -0.0492, -0.0438, -0.0442,  0.0381, -0.0366, -0.0371,\n",
      "         0.0264,  0.0316,  0.0392,  0.0068, -0.0249, -0.0150,  0.0074, -0.0048,\n",
      "        -0.0159,  0.0469, -0.0368,  0.0129, -0.0005, -0.0070,  0.0336, -0.0133,\n",
      "         0.0092,  0.0221,  0.0243,  0.0148, -0.0364,  0.0302,  0.0073,  0.0340,\n",
      "         0.0352,  0.0168,  0.0031, -0.0332, -0.0451,  0.0055, -0.0192,  0.0312,\n",
      "         0.0153, -0.0057, -0.0034,  0.0173, -0.0460, -0.0174,  0.0491,  0.0136,\n",
      "         0.0439,  0.0067,  0.0334, -0.0224, -0.0109,  0.0434, -0.0194,  0.0303,\n",
      "        -0.0065,  0.0224, -0.0377, -0.0255,  0.0491, -0.0194, -0.0301,  0.0321,\n",
      "         0.0400, -0.0425, -0.0273, -0.0128,  0.0107,  0.0472,  0.0132,  0.0070,\n",
      "         0.0121, -0.0002, -0.0054,  0.0079,  0.0116, -0.0258,  0.0228, -0.0226],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[ 0.0397, -0.0041,  0.0555,  ..., -0.0752, -0.0738,  0.0767],\n",
      "        [ 0.0640, -0.0258,  0.0791,  ...,  0.0747,  0.0165, -0.0440],\n",
      "        [ 0.0019,  0.0173,  0.0657,  ...,  0.0872, -0.0297, -0.0135],\n",
      "        ...,\n",
      "        [ 0.0110, -0.0574,  0.0699,  ..., -0.0822,  0.0135, -0.0689],\n",
      "        [ 0.0434,  0.0544, -0.0586,  ...,  0.0334, -0.0695,  0.0848],\n",
      "        [ 0.0551,  0.0700, -0.0249,  ...,  0.0875,  0.0467,  0.0347]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-8.7702e-02,  7.7851e-02, -3.3658e-03,  9.0561e-02, -6.7417e-02,\n",
      "        -7.1416e-02,  4.9447e-02, -1.7496e-02, -8.1852e-02,  4.5746e-02,\n",
      "         7.8712e-02, -3.7556e-02,  2.6435e-02, -1.8540e-02, -4.7487e-02,\n",
      "         2.9215e-02,  1.2224e-02,  6.6399e-02, -6.4936e-02, -6.2947e-02,\n",
      "         6.1429e-02, -2.5652e-02,  6.6666e-02,  2.8298e-02,  2.4563e-02,\n",
      "        -2.2919e-02,  7.8760e-02,  4.2675e-02, -2.8078e-02, -7.0653e-02,\n",
      "         7.9520e-02, -4.3263e-02,  5.4392e-02, -7.2673e-02, -2.0652e-03,\n",
      "         5.2518e-03,  4.1392e-02, -8.9342e-02,  4.7600e-02,  8.4311e-02,\n",
      "         4.0400e-03, -3.6979e-02, -3.5551e-02,  7.3322e-03,  2.6170e-02,\n",
      "        -1.0362e-02,  6.6218e-02,  4.0234e-02, -9.4622e-05, -4.5944e-02,\n",
      "        -1.9547e-02, -8.9819e-02, -6.7122e-02, -5.3926e-02, -4.0734e-02,\n",
      "        -4.5993e-02, -8.3388e-02,  8.8488e-02,  7.1031e-02,  4.8146e-02,\n",
      "        -1.3653e-02, -4.9812e-02, -7.6270e-02,  4.4615e-02, -8.4343e-02,\n",
      "         8.8751e-02, -7.0010e-02, -3.9236e-02,  2.5800e-02,  5.0256e-02,\n",
      "        -1.4531e-02, -7.3541e-02, -5.1807e-02,  1.2633e-02,  4.9676e-02,\n",
      "         6.7438e-04, -1.9880e-02,  8.0367e-02, -3.2470e-02, -4.4703e-02,\n",
      "         6.7496e-02,  6.5897e-02, -4.4277e-02,  6.9422e-03],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0929,  0.0555,  0.0624, -0.0717, -0.0813, -0.0957, -0.0031, -0.0089,\n",
      "          0.0052,  0.0463, -0.0686, -0.0602,  0.0407,  0.0778, -0.0241,  0.0427,\n",
      "         -0.0834, -0.0263, -0.1035, -0.0561, -0.0839,  0.0913, -0.0933, -0.0831,\n",
      "         -0.0350,  0.0719,  0.0021,  0.0216, -0.0848,  0.1066, -0.1044,  0.0125,\n",
      "          0.0138, -0.0109, -0.0283, -0.0672, -0.0072,  0.0790,  0.1083,  0.0111,\n",
      "          0.0639, -0.0242, -0.0009, -0.0474, -0.0528, -0.0774,  0.0573,  0.0151,\n",
      "          0.0091,  0.0369, -0.1028,  0.0147,  0.0172,  0.0590, -0.0756,  0.0792,\n",
      "          0.0234, -0.0591, -0.0006, -0.0103,  0.1019, -0.0488,  0.0477, -0.0457,\n",
      "          0.0433, -0.0701, -0.0343, -0.0260, -0.0120, -0.0163,  0.1075,  0.0624,\n",
      "          0.1063,  0.0626,  0.0424, -0.0023,  0.0897,  0.0312, -0.0589,  0.0723,\n",
      "          0.0812,  0.0555,  0.0376,  0.0715],\n",
      "        [-0.0044,  0.0527,  0.0203,  0.0702,  0.0393,  0.0788,  0.0609, -0.0885,\n",
      "          0.0317, -0.0136, -0.0544, -0.0623, -0.0016, -0.0462,  0.0992, -0.1041,\n",
      "         -0.0930, -0.0218, -0.1013,  0.1062, -0.0305,  0.0013, -0.0121, -0.0801,\n",
      "         -0.0407,  0.0084,  0.0095, -0.0951,  0.0846, -0.0266,  0.0208, -0.0058,\n",
      "         -0.0409, -0.0489, -0.0131, -0.0672, -0.0383,  0.0662, -0.0301, -0.0474,\n",
      "          0.1071,  0.0812, -0.0610, -0.0305, -0.0836, -0.0784,  0.0659,  0.0846,\n",
      "         -0.0817, -0.0976,  0.0925,  0.0615,  0.0198, -0.0770, -0.0338, -0.0240,\n",
      "          0.0510,  0.0962, -0.0366,  0.0318,  0.0770,  0.0179, -0.0754, -0.0273,\n",
      "         -0.0992, -0.0707,  0.0832, -0.0081,  0.0175, -0.0014,  0.1044,  0.0228,\n",
      "         -0.0993,  0.1028, -0.0606,  0.0500, -0.0308,  0.0543, -0.0358,  0.0549,\n",
      "         -0.0936, -0.0317, -0.0572,  0.0993],\n",
      "        [ 0.0270,  0.0267, -0.1033, -0.1041,  0.0867,  0.0063, -0.1036, -0.0734,\n",
      "          0.0625,  0.1024, -0.0031,  0.0510,  0.0042, -0.0291, -0.1052,  0.1017,\n",
      "         -0.0399, -0.0647,  0.0579, -0.0190, -0.0701, -0.0478,  0.0019, -0.1073,\n",
      "          0.0382,  0.0768, -0.0442,  0.0957,  0.0513, -0.0772,  0.0894,  0.0827,\n",
      "          0.0076, -0.0890,  0.0236, -0.1063,  0.0162, -0.0183,  0.0315, -0.0776,\n",
      "         -0.0777,  0.0680,  0.0664,  0.0813,  0.0824,  0.0424,  0.0686,  0.0559,\n",
      "         -0.1027, -0.0844,  0.0561, -0.0841, -0.0328,  0.0284,  0.0865, -0.0262,\n",
      "          0.0979, -0.0205, -0.1017, -0.0534, -0.0911, -0.0746, -0.0528,  0.0193,\n",
      "         -0.0645,  0.0452, -0.0285,  0.0167,  0.0902,  0.0626,  0.0638,  0.0509,\n",
      "          0.1070,  0.0856,  0.0264,  0.0319,  0.0257, -0.0049,  0.0303,  0.0592,\n",
      "         -0.0076,  0.0223,  0.0488,  0.0616],\n",
      "        [ 0.0012,  0.1088,  0.0783,  0.0585,  0.1062, -0.0742, -0.0898, -0.0275,\n",
      "          0.0184,  0.0512, -0.0078, -0.0097, -0.0109,  0.0455,  0.0604, -0.0293,\n",
      "         -0.0998,  0.0887,  0.0846, -0.0508, -0.0193,  0.0029,  0.0747, -0.0234,\n",
      "          0.0640,  0.0553, -0.0091, -0.0557,  0.0157,  0.1070, -0.0301, -0.0263,\n",
      "         -0.1002, -0.1009, -0.0845,  0.0213,  0.1012, -0.0529, -0.0760,  0.0489,\n",
      "          0.0161, -0.0390, -0.0689, -0.0536,  0.0302, -0.0423,  0.0418, -0.0430,\n",
      "         -0.1018, -0.0440, -0.0730, -0.0197, -0.0643,  0.0815, -0.1007, -0.0880,\n",
      "          0.0372, -0.0341,  0.0148, -0.0201,  0.0601,  0.0747, -0.1091,  0.1080,\n",
      "         -0.0376,  0.0675,  0.0981,  0.0517,  0.0586,  0.0788, -0.0120,  0.0680,\n",
      "         -0.0629,  0.0466,  0.0457,  0.0232,  0.0282,  0.0973, -0.0890,  0.0663,\n",
      "          0.0613,  0.0321, -0.0634, -0.0211],\n",
      "        [-0.1084, -0.0249,  0.0128, -0.0595, -0.0624, -0.0065,  0.0085,  0.1047,\n",
      "          0.0077,  0.0111,  0.0248, -0.0525,  0.0355,  0.0557, -0.0285,  0.0552,\n",
      "         -0.0707,  0.0935,  0.0592,  0.0812,  0.0563,  0.0389, -0.1083,  0.0786,\n",
      "         -0.0279, -0.0660,  0.1019, -0.1061, -0.0685,  0.0064, -0.0403, -0.0511,\n",
      "         -0.0840, -0.1053,  0.0440,  0.0664,  0.0362,  0.0957, -0.0814, -0.0577,\n",
      "         -0.0779, -0.0510, -0.0715, -0.0265, -0.0166, -0.0364,  0.0355,  0.0742,\n",
      "          0.0817,  0.1025,  0.0268, -0.1074, -0.0390, -0.0474, -0.0747,  0.0588,\n",
      "         -0.0488, -0.0880,  0.0908, -0.0294,  0.0610, -0.0090, -0.0865,  0.0795,\n",
      "          0.0197,  0.0403,  0.0087, -0.0999,  0.0015,  0.0641,  0.0536,  0.0390,\n",
      "          0.1032, -0.1020, -0.0609, -0.0084,  0.0123,  0.1073,  0.0807,  0.0227,\n",
      "          0.0476,  0.0485,  0.0248, -0.0600],\n",
      "        [-0.0655, -0.1037, -0.0289,  0.0525,  0.0737,  0.0429, -0.0132,  0.0311,\n",
      "         -0.0807,  0.0334,  0.0993, -0.0871, -0.0993,  0.0531,  0.0500, -0.0491,\n",
      "          0.0552, -0.0063,  0.0667, -0.0413,  0.0652,  0.0058,  0.1013, -0.0396,\n",
      "         -0.0767, -0.0381,  0.0276,  0.0944, -0.0469, -0.0707,  0.0377,  0.0807,\n",
      "          0.0997, -0.0656, -0.0221, -0.0778, -0.0034,  0.0186,  0.0648, -0.0919,\n",
      "          0.0043,  0.0765, -0.0468,  0.0415,  0.0539,  0.0342, -0.0480,  0.0479,\n",
      "         -0.0441, -0.0326,  0.0259,  0.0362,  0.0589,  0.0563,  0.0160, -0.0478,\n",
      "         -0.0068,  0.0965, -0.0039,  0.0757,  0.0287, -0.0057, -0.0261, -0.0344,\n",
      "          0.0393, -0.1016,  0.1058, -0.0014, -0.0211,  0.0564, -0.0653,  0.0514,\n",
      "          0.0218,  0.0539, -0.0552,  0.0445, -0.0503,  0.0834,  0.0953,  0.1034,\n",
      "         -0.1067,  0.0598, -0.0821, -0.0333],\n",
      "        [ 0.0374,  0.0799, -0.0314, -0.0074,  0.0938,  0.0627,  0.0117, -0.0696,\n",
      "         -0.0653, -0.0411,  0.0528, -0.0918, -0.0401,  0.0175, -0.1009, -0.0142,\n",
      "         -0.0960, -0.0083, -0.0363,  0.0609,  0.0136,  0.0623, -0.0665, -0.0711,\n",
      "         -0.0455,  0.0354,  0.0839, -0.0965,  0.0153,  0.0833,  0.1032,  0.0672,\n",
      "         -0.0259,  0.0434, -0.0031,  0.0559, -0.0617,  0.0459, -0.0352, -0.0039,\n",
      "          0.0752, -0.0873, -0.0638,  0.0419, -0.0490,  0.0840, -0.0353, -0.0605,\n",
      "         -0.1020,  0.1083,  0.0133,  0.0209,  0.0782,  0.0377,  0.0189, -0.0668,\n",
      "          0.0760,  0.0026,  0.0065, -0.0189, -0.0747, -0.1004,  0.0774,  0.0379,\n",
      "         -0.0792, -0.0919,  0.1051,  0.0875,  0.0612, -0.0141, -0.0432,  0.0519,\n",
      "         -0.0174,  0.0388,  0.0044, -0.0394, -0.0690, -0.0935, -0.0332,  0.0858,\n",
      "         -0.1043, -0.0206,  0.0411,  0.0017],\n",
      "        [ 0.0105,  0.0407, -0.0384,  0.0166,  0.0145, -0.0710, -0.1064,  0.0078,\n",
      "          0.0169, -0.0985, -0.0033, -0.0649, -0.0175, -0.0591,  0.0413,  0.0800,\n",
      "         -0.0111,  0.0138,  0.0536, -0.0113,  0.0849, -0.1019, -0.0866, -0.0423,\n",
      "          0.0200,  0.0750, -0.1089,  0.0594, -0.0018, -0.0866,  0.0294,  0.0375,\n",
      "         -0.0459,  0.0239,  0.0688, -0.0106,  0.0858,  0.1042,  0.0922, -0.0623,\n",
      "          0.0204,  0.0131,  0.0528,  0.0556, -0.0411,  0.0502, -0.0214, -0.0482,\n",
      "          0.0570, -0.0700, -0.0810,  0.0922, -0.0856,  0.0295,  0.1060, -0.0190,\n",
      "          0.0563, -0.0099,  0.0569,  0.0313, -0.0725,  0.0986,  0.0066,  0.0162,\n",
      "          0.0766, -0.0956,  0.0797, -0.0217,  0.0175,  0.0603, -0.0137,  0.0093,\n",
      "          0.0779,  0.0695, -0.0548, -0.1038,  0.0402, -0.0506,  0.0961,  0.0377,\n",
      "         -0.0429, -0.0440,  0.0206,  0.0313],\n",
      "        [-0.0070, -0.1062, -0.0555,  0.0969, -0.0377,  0.0647,  0.0610, -0.0814,\n",
      "         -0.0910,  0.0723, -0.0177,  0.1000,  0.1068, -0.0259,  0.0160,  0.0929,\n",
      "          0.0296,  0.0872, -0.0759,  0.0930, -0.0346, -0.0254, -0.0348, -0.0650,\n",
      "         -0.0219, -0.1046,  0.0757,  0.0774,  0.0193, -0.0777, -0.0132, -0.1041,\n",
      "         -0.0920, -0.0542, -0.1062,  0.0766,  0.0359, -0.1004,  0.0489,  0.0207,\n",
      "         -0.0926,  0.0145, -0.0893,  0.0191, -0.0153,  0.0439, -0.0394, -0.0274,\n",
      "         -0.0932, -0.0837,  0.0960,  0.0544,  0.1024,  0.0753,  0.0127,  0.0649,\n",
      "          0.1020,  0.0986,  0.0594, -0.0744, -0.0128,  0.0369, -0.0848,  0.0373,\n",
      "          0.0492, -0.1080, -0.0978, -0.0582, -0.0588,  0.0525,  0.0369,  0.0614,\n",
      "         -0.0036,  0.0315,  0.0948,  0.0712,  0.0849,  0.0447, -0.0384, -0.1016,\n",
      "          0.0189, -0.1019, -0.0173, -0.0944],\n",
      "        [-0.0733, -0.0894, -0.0372, -0.0362,  0.0247, -0.0255,  0.0150,  0.0100,\n",
      "         -0.0534,  0.0244,  0.0271,  0.0107,  0.0798, -0.1065,  0.1074,  0.0254,\n",
      "         -0.0429,  0.1037, -0.0031, -0.0857,  0.0258,  0.0568, -0.0090, -0.0485,\n",
      "          0.1017, -0.0096, -0.1020, -0.1045, -0.0589, -0.0038,  0.0974, -0.0695,\n",
      "         -0.0629,  0.0832,  0.0388, -0.0271, -0.0117, -0.0187,  0.0346, -0.0745,\n",
      "         -0.0881,  0.0887, -0.0436, -0.0897,  0.0446,  0.0539, -0.0960,  0.0408,\n",
      "         -0.0958, -0.0092, -0.0672, -0.0618,  0.0197,  0.0601, -0.0869,  0.0988,\n",
      "         -0.0389,  0.0172, -0.0840,  0.0021, -0.0400,  0.0624,  0.0078, -0.0964,\n",
      "          0.0795, -0.0817, -0.0273, -0.0432,  0.0505, -0.1033, -0.0199, -0.0306,\n",
      "          0.0396, -0.0575, -0.0060, -0.1038,  0.0950,  0.0442,  0.0609, -0.0542,\n",
      "         -0.0672,  0.0301, -0.0745, -0.0822]], requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0903, -0.0944,  0.0184, -0.0265,  0.0201,  0.0469,  0.0768, -0.1078,\n",
      "         0.0519,  0.0044], requires_grad=True)]\n",
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let try a random 32x32 input\n",
    "Note: Expected input size to this net(LeNet) is 32x32. To use this net on\n",
    "MNIST dataset, please resize the images from the dataset to 32x32.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0649, -0.1442,  0.0727, -0.0277,  0.0536,  0.0148,  0.0673, -0.0857,\n",
      "          0.0316, -0.0228]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Zero the gradient buffers of all parameters and backprops with random\n",
    "gradients:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.nn`` only supports mini-batches. The entire ``torch.nn``\n",
    "    package only supports inputs that are a mini-batch of samples, and not\n",
    "    a single sample.\n",
    "\n",
    "    For example, ``nn.Conv2d`` will take in a 4D Tensor of\n",
    "    ``nSamples x nChannels x Height x Width``.\n",
    "\n",
    "    If you have a single sample, just use ``input.unsqueeze(0)`` to add\n",
    "    a fake batch dimension.\n",
    "</p></div>\n",
    "\n",
    "Before proceeding further, let's recap all the classes you’ve seen so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Recap:**\n",
    "  -  ``torch.Tensor`` - A *multi-dimensional array* with support for autograd\n",
    "     operations like ``backward()``. Also *holds the gradient* w.r.t. the\n",
    "     tensor.\n",
    "  -  ``nn.Module`` - Neural network module. *Convenient way of\n",
    "     encapsulating parameters*, with helpers for moving them to GPU,\n",
    "     exporting, loading, etc.\n",
    "  -  ``nn.Parameter`` - A kind of Tensor, that is *automatically\n",
    "     registered as a parameter when assigned as an attribute to a*\n",
    "     ``Module``.\n",
    "  -  ``autograd.Function`` - Implements *forward and backward definitions\n",
    "     of an autograd operation*. Every ``Tensor`` operation, creates at\n",
    "     least a single ``Function`` node, that connects to functions that\n",
    "     created a ``Tensor`` and *encodes its history*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**At this point, we covered:**\n",
    "  -  Defining a neural network\n",
    "  -  Processing inputs and calling backward\n",
    "\n",
    "**Still Left:**\n",
    "  -  Computing the loss\n",
    "  -  Updating the weights of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Loss Function\n",
    "-------------\n",
    "A loss function takes the (output, target) pair of inputs, and computes a\n",
    "value that estimates how far away the output is from the target.\n",
    "\n",
    "There are several different\n",
    "`loss functions <https://pytorch.org/docs/nn.html#loss-functions>`_ under the\n",
    "nn package .\n",
    "A simple loss is: ``nn.MSELoss`` which computes the mean-squared error\n",
    "between the input and the target.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3441, -0.6741, -1.0023, -0.7223,  0.8283, -0.5215,  1.7272,  0.1900,\n",
      "        -0.4528, -0.8494])\n",
      "tensor([[ 0.3441, -0.6741, -1.0023, -0.7223,  0.8283, -0.5215,  1.7272,  0.1900,\n",
      "         -0.4528, -0.8494]])\n",
      "tensor(0.6634, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "print(target)\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "print(target)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, if you follow ``loss`` in the backward direction, using its\n",
    "``.grad_fn`` attribute, you will see a graph of computations that looks\n",
    "like this:\n",
    "\n",
    "::\n",
    "\n",
    "    input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "          -> view -> linear -> relu -> linear -> relu -> linear\n",
    "          -> MSELoss\n",
    "          -> loss\n",
    "\n",
    "So, when we call ``loss.backward()``, the whole graph is differentiated\n",
    "w.r.t. the loss, and all Tensors in the graph that has ``requires_grad=True``\n",
    "will have their ``.grad`` Tensor accumulated with the gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For illustration, let us follow a few steps backward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x0000021A86EA58C8>\n",
      "<AddmmBackward object at 0x0000021A86EA5AC8>\n",
      "<AccumulateGrad object at 0x0000021A86EA58C8>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Backprop\n",
    "--------\n",
    "To backpropagate the error all we have to do is to ``loss.backward()``.\n",
    "You need to clear the existing gradients though, else gradients will be\n",
    "accumulated to existing gradients.\n",
    "\n",
    "\n",
    "Now we shall call ``loss.backward()``, and have a look at conv1's bias\n",
    "gradients before and after the backward.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0152,  0.0101,  0.0002,  0.0037, -0.0074, -0.0026])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, we have seen how to use loss functions.\n",
    "\n",
    "**Read Later:**\n",
    "\n",
    "  The neural network package contains various modules and loss functions\n",
    "  that form the building blocks of deep neural networks. A full list with\n",
    "  documentation is [here](https://pytorch.org/docs/nn).\n",
    "\n",
    "**The only thing left to learn is:**\n",
    "\n",
    "  - Updating the weights of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Update the weights\n",
    "------------------\n",
    "The simplest update rule used in practice is the Stochastic Gradient\n",
    "Descent (SGD):\n",
    "\n",
    "     ``weight = weight - learning_rate * gradient``\n",
    "\n",
    "We can implement this using simple python code:\n",
    "\n",
    "```python\n",
    "    learning_rate = 0.01\n",
    "    for f in net.parameters():\n",
    "        f.data.sub_(f.grad.data * learning_rate)\n",
    "```\n",
    "\n",
    "However, as you use neural networks, you want to use various different\n",
    "update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc.\n",
    "To enable this, we built a small package: ``torch.optim`` that\n",
    "implements all these methods. Using it is very simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[ 6.7859e-02, -1.9005e-01,  1.8810e-01,  1.2923e-02,  8.9450e-03],\n",
       "          [-3.2996e-02, -1.3114e-01,  1.1513e-01, -1.0494e-01,  7.1926e-02],\n",
       "          [-8.4603e-02, -1.6450e-01,  5.2596e-02, -6.8345e-02, -1.5887e-01],\n",
       "          [ 1.4162e-01,  6.5854e-02, -4.4675e-02,  1.1221e-01,  1.6472e-02],\n",
       "          [-9.0864e-02, -1.1963e-01,  1.6023e-02,  1.9505e-01, -5.3095e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.6647e-01,  1.8772e-01,  4.1453e-02, -1.0453e-01, -6.1271e-02],\n",
       "          [ 1.9138e-01, -3.7036e-02, -1.8216e-02, -8.0275e-02, -3.9518e-02],\n",
       "          [ 1.1836e-01,  1.4361e-01,  3.8874e-02,  1.1272e-01,  3.6754e-02],\n",
       "          [ 1.7342e-02,  1.8355e-01, -6.9731e-02,  1.8142e-03,  4.8517e-02],\n",
       "          [ 1.3354e-01, -1.3123e-01, -9.5407e-02, -1.7106e-01, -1.1009e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.8091e-01, -1.5856e-01,  1.5622e-01,  5.2095e-02,  1.5880e-01],\n",
       "          [ 1.8159e-01, -1.3252e-01,  1.1634e-01,  1.5389e-01, -1.6238e-01],\n",
       "          [-1.7970e-01, -4.8288e-02,  1.9923e-01,  6.2833e-02, -1.1773e-01],\n",
       "          [ 2.5203e-02, -1.4416e-01,  1.8441e-01,  8.4829e-02, -1.8186e-01],\n",
       "          [ 7.6809e-02, -4.1912e-02, -1.0651e-01, -1.5490e-01, -6.7093e-03]]],\n",
       "\n",
       "\n",
       "        [[[-1.3528e-01, -2.3538e-02,  1.2213e-01,  1.1658e-01,  8.5840e-02],\n",
       "          [-6.1797e-02,  6.3212e-02, -1.3951e-01,  9.7108e-02,  1.5059e-01],\n",
       "          [-5.8351e-03,  8.4192e-05,  1.4057e-01,  7.7183e-02,  4.9790e-02],\n",
       "          [-5.2907e-02,  3.4174e-02,  2.3181e-02,  1.9831e-01,  2.6256e-02],\n",
       "          [-1.5182e-01,  1.6531e-01,  1.3799e-01, -1.4652e-01, -1.5169e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 8.1680e-02, -8.8775e-02,  2.7048e-02,  1.5494e-01,  1.4895e-01],\n",
       "          [-3.9487e-03,  1.2865e-01,  1.6481e-01,  2.1917e-02, -1.9916e-01],\n",
       "          [-1.1557e-01,  1.1652e-01,  5.3403e-03,  1.5616e-01, -1.2141e-01],\n",
       "          [-8.0182e-02,  6.5489e-02, -2.9143e-02,  1.5819e-01, -8.6824e-02],\n",
       "          [ 1.6346e-01,  1.6408e-01,  1.0959e-01, -3.7340e-03,  7.0282e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.2781e-02,  1.8091e-01,  1.8709e-01, -1.8869e-01,  1.4149e-01],\n",
       "          [-7.3848e-02,  1.0288e-02, -1.3038e-01, -1.9502e-01, -1.2815e-01],\n",
       "          [ 3.9228e-02,  2.4825e-02, -1.3809e-01, -1.0910e-02, -1.5166e-01],\n",
       "          [ 9.1991e-02, -1.4077e-01,  5.4018e-02, -1.8798e-01, -1.6598e-01],\n",
       "          [-1.3172e-01,  4.4146e-04,  4.4940e-02, -1.1876e-01,  1.0857e-01]]]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = next(net.parameters())\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f1.data.sub_(f1.grad * 0.01)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    ".. Note::\n",
    "\n",
    "      Observe how gradient buffers had to be manually set to zero using\n",
    "      ``optimizer.zero_grad()``. This is because gradients are accumulated\n",
    "      as explained in `Backprop`_ section.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
