{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Sigmo誰de\" data-toc-modified-id=\"Sigmo誰de-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Sigmo誰de</a></span></li><li><span><a href=\"#Softmax\" data-toc-modified-id=\"Softmax-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Softmax</a></span></li><li><span><a href=\"#Binary-Cross-Entropy\" data-toc-modified-id=\"Binary-Cross-Entropy-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Binary Cross Entropy</a></span></li><li><span><a href=\"#Cross-Entropy\" data-toc-modified-id=\"Cross-Entropy-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Cross Entropy</a></span></li><li><span><a href=\"#Shape\" data-toc-modified-id=\"Shape-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Shape</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "|Problem type|Last-layer activation|Loss function|Example|\n",
    "|------------|---------------------|-------------|-------|\n",
    "|Binary classification|sigmoid|binary cross entropy|Dog vs cat, Sentiment analysis(pos/neg)|\n",
    "|Multi-class, single-label classification|softmax|cross entropy|MNIST has 10 classes single label (one prediction is one digit)|\n",
    "|Multi-class, multi-label classification|sigmoid|binary cross entropy|News tags classification, one blog can have multiple tags\n",
    "|Regression to arbitrary values|None|mse|Predict house price(an integer/float point)|\n",
    "|Regression to values between 0 and 1|sigmoid|mse or binary crossentropy|Engine health assessment where 0 is broken, 1 is new|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sigmo誰de\n",
    "\n",
    "$$\\text{Sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.arange(-10,10,0.01,dtype='f')\n",
    "plt.plot(x,torch.sigmoid(torch.from_numpy(x)).numpy())\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Softmax\n",
    "\n",
    "$$\\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "input = torch.randn(2, 3)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "out1 = nn.Softmax(dim=0)(input)\n",
    "print(out1)\n",
    "print(out1.sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "out2 = nn.Softmax(dim=1)(input)\n",
    "print(out2)\n",
    "print(out2.sum(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Binary Cross Entropy\n",
    "\n",
    "`torch.nn.BCELoss(weight=None, size_average=None, reduce=None, reduction='mean')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Creates a criterion that measures the Binary Cross Entropy\n",
    "between the target and the output:\n",
    "\n",
    "The loss can be described as:\n",
    "\n",
    "$$\n",
    "        \\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad\n",
    "$$\n",
    "\n",
    "$$\n",
    "        l_n = - w_n \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right],\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "where $N$ is the batch size. If reduce is ``True``, then\n",
    "\n",
    "$$\n",
    "        \\ell(x, y) = \\begin{cases}\n",
    "            \\operatorname{mean}(L), & \\text{if}\\; \\text{size_average} = \\text{True},\\\\\n",
    "            \\operatorname{sum}(L),  & \\text{if}\\; \\text{size_average} = \\text{False}.\n",
    "        \\end{cases}\n",
    "$$\n",
    "\n",
    "This is used for measuring the error of a reconstruction in for example\n",
    "an auto-encoder. Note that the targets `y` should be numbers\n",
    "between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "target = torch.empty(3).random_(2)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "output = loss(m(input), target)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "output.backward()\n",
    "-input.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross Entropy\n",
    "\n",
    "`CrossEntropyLoss(weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean')`\n",
    "\n",
    "his criterion combines `nn.LogSoftmax` and `nn.NLLLoss` in one single class.\n",
    "\n",
    "It is useful when training a classification problem with `C` classes.\n",
    "If provided, the optional argument `weight` should be a 1D `Tensor`\n",
    "assigning weight to each of the classes.\n",
    "This is particularly useful when you have an unbalanced training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `input` is expected to contain scores for each class.\n",
    "\n",
    "`input` has to be a Tensor of size either $(minibatch, C)$ or\n",
    "$(minibatch, C, d_1, d_2, ..., d_K)$\n",
    "with $K \\geq 2$ for the `K`-dimensional case (described later).\n",
    "\n",
    "This criterion expects a class index (0 to `C-1`) as the\n",
    "`target` for each value of a 1D tensor of size `minibatch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The loss can be described as:\n",
    "\n",
    "$$\n",
    "        \\text{loss}(x, class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])}\\right)\n",
    "                       = -x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right)\n",
    "$$\n",
    "\n",
    "or in the case of the `weight` argument being specified:\n",
    "\n",
    "$$\n",
    "\\text{loss}(x, class) = weight[class] \\left(-x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The losses are averaged across observations for each minibatch.\n",
    "\n",
    "Can also be used for higher dimension inputs, such as 2D images, by providing\n",
    "an input of size $(minibatch, C, d_1, d_2, ..., d_K)$ with $K \\geq 2$,\n",
    "where $K$ is the number of dimensions, and a target of appropriate shape\n",
    "(see below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape\n",
    "\n",
    "- Input: $(N, C)$ where `C = number of classes`, or $(N, C, d_1, d_2, ..., d_K)$ with $K \\geq 2$ in the case of `K`-dimensional loss.\n",
    "- Target: $(N)$ where each value is $0 \\leq \\text{targets}[i] \\leq C-1$, or $(N, d_1, d_2, ..., d_K)$ with $K \\geq 2$ in the case of K-dimensional loss.\n",
    "- Output: scalar. If reduce is ``False``, then the same size as the target: $(N)$, or $(N, d_1, d_2, ..., d_K)$ with $K \\geq 2$ in the case of K-dimensional loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "output = loss(input, target)\n",
    "print(output)\n",
    "output.backward()\n",
    "print(-input.grad)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
